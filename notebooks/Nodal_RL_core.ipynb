{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/JacobFV/Nodal-RL/blob/master/notebooks/Nodal_RL_core.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.2.0', '5.4.0', 175)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION, tf.version.COMPILER_VERSION, tf.version.GRAPH_DEF_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3EkKhQB-RVw"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    Generic Node base class\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 p = 1,\n",
    "                 default_parent_biasing_params = {\n",
    "                     \"w_otarget\": 1.0,\n",
    "                     \"o_target_lambda\": 1.0\n",
    "                 }):\n",
    "        \"\"\"\n",
    "        initializese abstract node class\n",
    "        \n",
    "        :param p: period for timesteps. number\n",
    "        :param default_parent_biasing_params:\n",
    "                default biasing_params for parents\n",
    "                Dict<str,number>\n",
    "                \n",
    "                properties:\n",
    "                    - otarget weight: \"w_otarget\" -> number\n",
    "                    - recency otarget weight decay factor: \"o_target_lambda\" -> number\n",
    "        \n",
    "        :return: returns Node\n",
    "        \"\"\"\n",
    "        \n",
    "        self.p = p\n",
    "        self.default_parent_biasing_params = default_parent_biasing_params\n",
    "        \n",
    "        #initialize stateful variables\n",
    "        self.t = 0\n",
    "        \n",
    "        \"\"\"\n",
    "        data for each parent node\n",
    "        Dict<Node, Dict<str, number>>\n",
    "\n",
    "        usage: [Node][\"property\"] = value\n",
    "\n",
    "        properties:\n",
    "            - otarget weight: 'w_otarget' -> number\n",
    "            - recency otarget weight decay factor: 'o_target_lambda' -> number\n",
    "        \"\"\"\n",
    "        self.parent_biasing_params = {}\n",
    "        \n",
    "        \"\"\"\n",
    "        actual observations used from parents\n",
    "\n",
    "        NOTE: the parent may have more observations\n",
    "            in its `s` records that are not used by\n",
    "            `self` because they are at a finer timescale \n",
    "\n",
    "        dict<Node, dict<number,target observation>>\n",
    "        \"\"\"\n",
    "        self.parent_o = {}\n",
    "\n",
    "        \"\"\"\n",
    "        biasing target observations delivered to parents\n",
    "\n",
    "        dict<Node, dict<number,target observation>>\n",
    "        \"\"\"\n",
    "        self.parent_otarget = {}\n",
    "\n",
    "        \"\"\"\n",
    "        top down biasing target observations obeyed from children\n",
    "\n",
    "        NOTE: the children may have more target observations\n",
    "            in their `parent_otarget` records that are not used by\n",
    "            `self` because they are at a finer timescale \n",
    "\n",
    "        dict<Node, dict<number,target observation>>\n",
    "        \"\"\"\n",
    "        self.child_otarget = {}\n",
    "        \n",
    "        \"\"\"\n",
    "        record of states for each timestep\n",
    "        that `update` is called.\n",
    "\n",
    "        Some states are referenced by children\n",
    "\n",
    "        Dict<number, state>\n",
    "        \"\"\"\n",
    "        self.s = {}\n",
    "    \n",
    "    def __call__(self, *parents):\n",
    "        \"\"\"\n",
    "        register `parents` as its own parent and reach into\n",
    "        `parents` to register as child. Since this method simply\n",
    "        adds parents, it can be called multiple times with subsets\n",
    "        of parents or once with all parents to achieve equivalent\n",
    "        effects. Applies `self.default_parent_biasing_params` to\n",
    "        all parents. To manually specify `parent_biasing_params`,\n",
    "        pass in `parents` as dict<Node, parent_biasing_params>\n",
    "        \n",
    "        :param *parents: list of parent nodes to connect\n",
    "                or dict<Node, parent_biasing_params>\n",
    "        \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "\n",
    "        #convert parents to dict<Node, parent_biasing_params>\n",
    "        #regardless of how presented in args\n",
    "        if(isinstance(parents, list)):\n",
    "            parents = {\n",
    "                parent, self.default_parent_biasing_params\n",
    "                for parent in parents}\n",
    "            \n",
    "        for parent, parent_biasing_params in parents.items():\n",
    "            self._add_parent(parent, parent_biasing_params)\n",
    "            parent._add_child(self)\n",
    "    \n",
    "    def _add_parent(self, parent, parent_biasing_params):\n",
    "        self.parent_biasing_params[parent] = parent_biasing_params\n",
    "        self.parent_o[parent] = {}\n",
    "        self.parent_otarget[parent] = {}\n",
    "    \n",
    "    def _add_child(self, child):\n",
    "        self.child_otarget[child] = {}\n",
    "\n",
    "    def update(self):\n",
    "        \"\"\"\n",
    "        update node's internal variables at time intervals `self.p`\n",
    "        This function should be overriden \n",
    "\n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        raise NotImplemented()\n",
    "\n",
    "    def closest_record(self, dictionary, time):\n",
    "        \"\"\"\n",
    "        Identify highest indexed record in `dictionary` \n",
    "        that is less than or equal to `time`\n",
    "        \n",
    "        NOTE: call from Node containing dictionary.\n",
    "        because later vesions of this algorithm may use\n",
    "        `self.p` to jump ahead intelligently\n",
    "        \n",
    "        :param dictionary: dict<number, obj> to query\n",
    "        :param time: time to query for closest entries to\n",
    "        \n",
    "        :return: returns closest matching (time, record) record\n",
    "        \"\"\"\n",
    "        \n",
    "        for tau in dictionary.keys().reverse():\n",
    "            if tau <= time:\n",
    "                return tau, dictionary[tau]\n",
    "        \n",
    "        #errors\n",
    "        if not bool(dictionary):\n",
    "            raise Exception(\"`dictionary` empty\")\n",
    "        raise Exception(\"error searching for closest record to time:{time} in `dictionary`\")\n",
    "            \n",
    "    def child_obs_target_weighted_mean(self, other_terms=[]):\n",
    "        \"\"\"\n",
    "        computes weighted mean of child nodes'\n",
    "        target observations for `self` and `other_terms`\n",
    "        \n",
    "        The weighted mean observation target is\n",
    "        used by actuators and information nodes\n",
    "        \n",
    "        In computing `child_obs_target_weighted_mean`,\n",
    "        child node target observations are selected\n",
    "        by recency and added to `self.child_otarget`\n",
    "        for later training\n",
    "        \n",
    "        :param other_terms: (opt.) [(weight, value)] tuple list\n",
    "                of additional terms to incorperate into the\n",
    "                weighted mean calculation\n",
    "\n",
    "        :return: returns top down biasing target state  \n",
    "        \"\"\"\n",
    "        \n",
    "        weights = [weight for weight, value in other_terms]\n",
    "        values = [value for weight, value in other_terms]\n",
    "        \n",
    "        # for each child\n",
    "        for child, biasing_params in self.parent_biasing_params.items():\n",
    "            # find child target observation for time tau\n",
    "            # that is closest to `self.t`\n",
    "            tau, otarget = child.closest_record(child.s, self.t + self.p)\n",
    "            values.append(otarget)\n",
    "            \n",
    "            # compute weight in mean\n",
    "            weights.append(\n",
    "                biasing_params[\"w_otarget\"]\n",
    "                * CER(otarget)\n",
    "                * np.exp(\n",
    "                    -biasing_params[\"o_target_lambda\"]\n",
    "                    *(self.t + self.p - tau)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # save otarget for later training \n",
    "            self.child_otarget[child][tau] = otarget\n",
    "        \n",
    "        # compute weighted sum\n",
    "        weighted_sum = sum([\n",
    "            weight * value\n",
    "            for weight, value\n",
    "            in zip(weights, values)\n",
    "        ])\n",
    "        \n",
    "        # return weighted mean\n",
    "        return weighted_sum / sum(weights)\n",
    "\n",
    "    def save_information_episode(self, path):\n",
    "        \"\"\"\n",
    "        saves data to `path` for training later\n",
    "        \n",
    "        :param path: savepath\n",
    "        \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        #TODO maybe use pickle or shelve modules in addition to specific tf formats\n",
    "        raise NotImplemented()\n",
    "        \n",
    "    def load_information_episode(self, path):\n",
    "        \"\"\"\n",
    "        loads data from `path` for training\n",
    "        \n",
    "        :param path: savepath\n",
    "        \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        #TODO maybe use pickle or shelve modules in addition to specific tf formats\n",
    "        raise NotImplemented()\n",
    "\n",
    "    def reset_information_episode(self):\n",
    "        \"\"\"\n",
    "        resets all inference stateful variables\n",
    "        including observations and internal states\n",
    "\n",
    "        This means clearing:\n",
    "            `self.child_otarget`,\n",
    "            `self.parent otarget`,\n",
    "            `self.parent_o`,\n",
    "            and `self.s` dictionaries\n",
    "            \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        self.child_otarget.clear()\n",
    "        self.parent_otarget.clear()\n",
    "        self.s.clear()\n",
    "        self.parent_o.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLGvvSR2-aeF"
   },
   "outputs": [],
   "source": [
    "class Sensory_Node(Node):\n",
    "\n",
    "    def update(self):\n",
    "        #TODO\n",
    "        raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wbAGtvlK-cHd"
   },
   "outputs": [],
   "source": [
    "class Actuator_Node(Node):\n",
    "\n",
    "    def update():\n",
    "        #TODO\n",
    "        raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "il4MJ571-eYs"
   },
   "outputs": [],
   "source": [
    "class Information_Node(Node):\n",
    "\n",
    "    \n",
    "    def __init__(self, \n",
    "                 abstractor,\n",
    "                 predictor,\n",
    "                 policy,\n",
    "                 params = {\n",
    "                    \"pred-weight\":None,\n",
    "                    \"alpha-d1\":None,\n",
    "                    \"alpha-d2\":None,\n",
    "                    \"alpha-d3\":None\n",
    "                 },   \n",
    "                 ):\n",
    "        \"\"\"\n",
    "        initialize an `Information_Node`\n",
    "        \"\"\"\n",
    "        \n",
    "        self.params = params\n",
    "        self.abstractor\n",
    "        self.predictor\n",
    "        self.policy\n",
    "        \n",
    "        return\n",
    "\n",
    "    def update(self):\n",
    "        #TODO\n",
    "        raise NotImplemented()\n",
    "\n",
    "    def train(self,\n",
    "              lr=0.001,\n",
    "              verbose=True,\n",
    "              beta_piD=1,\n",
    "              beta_piC=1,\n",
    "              beta_piI=1,\n",
    "              beta_prD=1,\n",
    "              beta_prC=1,\n",
    "              ):\n",
    "        \"\"\"\n",
    "        trains `Information_Node`\n",
    "\n",
    "        :param lr: learning rate for optimizer\n",
    "        :param verbose: (True/False) log information verbosely\n",
    "        :param beta_piD: training hyperparameter. See 'Putting It All Togethor'\n",
    "        :param beta_piC: training hyperparameter. See 'Putting It All Togethor'\n",
    "        :param beta_piI: training hyperparameter. See 'Putting It All Togethor'\n",
    "        :param beta_prD: training hyperparameter. See 'Putting It All Togethor'\n",
    "        :param beta_prC: training hyperparameter. See 'Putting It All Togethor'\n",
    "        \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        #TODO\n",
    "        raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \n",
    "    def __init__(self, nodes):\n",
    "        \"\"\"\n",
    "        initializes the network\n",
    "        \n",
    "        :param nodes: all nodes that should be managed by the network. \n",
    "        \n",
    "        :return: returns initialized network\n",
    "        \"\"\"\n",
    "        self.nodes = nodes\n",
    "        self.time = 0\n",
    "    \n",
    "    def run(self, duration=-1, timestep=1):\n",
    "        \"\"\"\n",
    "        loops until time == duration\n",
    "        \n",
    "        :param duration: time to run for. -1 means forever\n",
    "        :param timestep: time increments used during `step`\n",
    "        \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        while self.time <= duration:\n",
    "            self.step(timestep)\n",
    "    \n",
    "    def step(self, timestep):\n",
    "        \"\"\"\n",
    "        increase timestep and check if any nodes should be updated\n",
    "        \n",
    "        :param timestep: positive time increment used\n",
    "        \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        self.time += timestep\n",
    "        #TODO\n",
    "        raise NotImplemented()\n",
    "    \n",
    "    def save_episode(self, path):\n",
    "        \"\"\"\n",
    "        save data to `path` for training\n",
    "        \n",
    "        :param path: savepath\n",
    "        \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        #TODO\n",
    "        raise NotImplemented()\n",
    "    \n",
    "    def load_episode(self, path):\n",
    "        \"\"\"\n",
    "        loads data from `path` for training\n",
    "        \n",
    "        :param path: savepath\n",
    "        \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        #TODO\n",
    "        raise NotImplemented()\n",
    "    \n",
    "    def reset_episode(self):\n",
    "        \"\"\"\n",
    "        resets all nodes' inference stateful variables\n",
    "        including observations and internal states\n",
    "            \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        #TODO\n",
    "        raise NotImplemented()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPZdmxyqEAjoQbH17fXsq9p",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Nodal RL core.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
