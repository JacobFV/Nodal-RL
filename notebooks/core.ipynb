{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/JacobFV/Nodal-RL/blob/master/notebooks/Nodal_RL_core.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.2.0', '5.4.0', 175)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION, tf.version.COMPILER_VERSION, tf.version.GRAPH_DEF_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3EkKhQB-RVw"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    Generic Node base class\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 p = 1,\n",
    "                 default_parent_biasing_params = {\n",
    "                     \"w_otarget\": 1.0,\n",
    "                     \"o_target_lambda\": 1.0\n",
    "                 }):\n",
    "        \"\"\"\n",
    "        initializese abstract node class\n",
    "        \n",
    "        :param p: period for timesteps. number\n",
    "        :param default_parent_biasing_params:\n",
    "                default biasing_params for parents\n",
    "                Dict<str,number>\n",
    "                \n",
    "                properties:\n",
    "                    - otarget weight: \"w_otarget\" -> number\n",
    "                    - recency otarget weight decay factor: \"o_target_lambda\" -> number\n",
    "        \n",
    "        :return: returns Node\n",
    "        \"\"\"\n",
    "        \n",
    "        self.p = p\n",
    "        \n",
    "        self.default_parent_biasing_params = default_parent_biasing_params\n",
    "        \n",
    "        \"\"\"\n",
    "        data for each parent node\n",
    "        Dict<Node, Dict<str, number>>\n",
    "\n",
    "        usage: [Node][\"property\"] = value\n",
    "\n",
    "        properties:\n",
    "            - otarget weight: 'w_otarget' -> number\n",
    "            - recency otarget weight decay factor: 'o_target_lambda' -> number\n",
    "        \"\"\"\n",
    "        self.parent_biasing_params = {}\n",
    "        \n",
    "        #initialize stateful variables\n",
    "        self.t = 0\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        actual observations used from parents\n",
    "\n",
    "        NOTE: the parent may have more observations\n",
    "            in its `s` records that are not used by\n",
    "            `self` because they are at a finer timescale \n",
    "\n",
    "        dict<Node, dict<number,target observation>>\n",
    "        \"\"\"\n",
    "        self.parent_o = {}\n",
    "\n",
    "        \"\"\"\n",
    "        biasing target observations delivered to parents\n",
    "\n",
    "        dict<Node, dict<number,target observation>>\n",
    "        \"\"\"\n",
    "        self.parent_otarget = {}\n",
    "\n",
    "        \"\"\"\n",
    "        top down biasing target observations obeyed from children\n",
    "\n",
    "        NOTE: the children may have more target observations\n",
    "            in their `parent_otarget` records that are not used by\n",
    "            `self` because they are at a finer timescale \n",
    "\n",
    "        dict<Node, dict<number,target observation>>\n",
    "        \"\"\"\n",
    "        self.child_otarget = {}\n",
    "        \n",
    "        \"\"\"\n",
    "        record of states for each timestep\n",
    "        that `update` is called.\n",
    "\n",
    "        Some states are referenced by children\n",
    "\n",
    "        Dict<number, state>\n",
    "        \"\"\"\n",
    "        self.s = {}\n",
    "    \n",
    "    def __call__(self, *parents):\n",
    "        \"\"\"\n",
    "        register `parents` as its own parent and reach into\n",
    "        `parents` to register as child. Since this method simply\n",
    "        adds parents, it can be called multiple times with subsets\n",
    "        of parents or once with all parents to achieve equivalent\n",
    "        effects. Applies `self.default_parent_biasing_params` to\n",
    "        all parents. To manually specify `parent_biasing_params`,\n",
    "        pass in `parents` as dict<Node, parent_biasing_params>\n",
    "        \n",
    "        :param *parents: list of parent nodes to connect\n",
    "                or dict<Node, parent_biasing_params>\n",
    "        \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "\n",
    "        #convert parents to dict<Node, parent_biasing_params>\n",
    "        #regardless of how presented in args\n",
    "        if(isinstance(parents, list)):\n",
    "            parents = {\n",
    "                parent, self.default_parent_biasing_params\n",
    "                for parent in parents}\n",
    "            \n",
    "        for parent, parent_biasing_params in parents.items():\n",
    "            self._add_parent(parent, parent_biasing_params)\n",
    "            parent._add_child(self)\n",
    "    \n",
    "    def _add_parent(self, parent, parent_biasing_params):\n",
    "        self.parent_biasing_params[parent] = parent_biasing_params\n",
    "        self.parent_o[parent] = {}\n",
    "        self.parent_otarget[parent] = {}\n",
    "    \n",
    "    def _add_child(self, child):\n",
    "        self.child_otarget[child] = {}\n",
    "\n",
    "    def update(self, time):\n",
    "        \"\"\"\n",
    "        update node's internal variables at time intervals `self.p`\n",
    "        This function should be overriden \n",
    "        \n",
    "        :param time: node time when updated\n",
    "\n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        raise NotImplemented()\n",
    "\n",
    "    def closest_record(self, dictionary, time):\n",
    "        \"\"\"\n",
    "        Identify highest indexed record in `dictionary` \n",
    "        that is less than or equal to `time`\n",
    "        \n",
    "        NOTE: call from Node containing dictionary.\n",
    "        because later vesions of this algorithm may use\n",
    "        `self.p` to jump ahead intelligently\n",
    "        \n",
    "        :param dictionary: dict<number, obj> to query\n",
    "        :param time: time to query for closest entries to\n",
    "        \n",
    "        :return: returns closest matching (time, record) record\n",
    "        \"\"\"\n",
    "        \n",
    "        for tau in dictionary.keys().reverse():\n",
    "            if tau <= time:\n",
    "                return tau, dictionary[tau]\n",
    "        \n",
    "        #errors\n",
    "        if not bool(dictionary):\n",
    "            raise Exception(\"`dictionary` empty\")\n",
    "        raise Exception(\"error searching for closest record to time:{time} in `dictionary`\")\n",
    "            \n",
    "    def child_obs_target_weighted_mean(self, other_terms=[]):\n",
    "        \"\"\"\n",
    "        computes weighted mean of child nodes'\n",
    "        target observations for `self` and `other_terms`\n",
    "        \n",
    "        The weighted mean observation target is\n",
    "        used by actuators and information nodes\n",
    "        \n",
    "        In computing `child_obs_target_weighted_mean`,\n",
    "        child node target observations are selected\n",
    "        by recency and added to `self.child_otarget`\n",
    "        for later training\n",
    "        \n",
    "        :param other_terms: (opt.) [(weight, value)] tuple list\n",
    "                of additional terms to incorperate into the\n",
    "                weighted mean calculation\n",
    "\n",
    "        :return: returns top down biasing target state  \n",
    "        \"\"\"\n",
    "        \n",
    "        weights = [weight for weight, value in other_terms]\n",
    "        values = [value for weight, value in other_terms]\n",
    "        \n",
    "        # for each child\n",
    "        for child, biasing_params in self.parent_biasing_params.items():\n",
    "            # find child target observation for time tau\n",
    "            # that is closest to `self.t`\n",
    "            tau, otarget = child.closest_record(child.s, self.t + self.p)\n",
    "            values.append(otarget)\n",
    "            \n",
    "            # compute weight in mean\n",
    "            weights.append(\n",
    "                biasing_params[\"w_otarget\"]\n",
    "                * CER(otarget)\n",
    "                * np.exp(\n",
    "                    -biasing_params[\"o_target_lambda\"]\n",
    "                    *(self.t + self.p - tau)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # save otarget for later training \n",
    "            self.child_otarget[child][tau] = otarget\n",
    "        \n",
    "        # compute weighted sum\n",
    "        weighted_sum = sum([\n",
    "            weight * value\n",
    "            for weight, value\n",
    "            in zip(weights, values)\n",
    "        ])\n",
    "        \n",
    "        # return weighted mean\n",
    "        return weighted_sum / sum(weights)\n",
    "\n",
    "    def save_information_episode(self, path):\n",
    "        \"\"\"\n",
    "        saves `self.parent_o` and `self.child_otarget`\n",
    "        to `path` for training later.\n",
    "        \n",
    "        This does NOT include subclass definitions, hyperparameters, etc.\n",
    "        Those entities must be reconstructed and then `load_information_episode`\n",
    "        \n",
    "        :param path: savepath\n",
    "                \n",
    "                The suffix of `path` detirmines decompression\n",
    "                employed. Valid options are: '.zip', '.gz', and '.bz2'\n",
    "                \n",
    "                `path` must use existing directories\n",
    "        \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        \n",
    "        datasets = {} # {'filename': tf.data.Dataset}\n",
    "        for parent, observations in self.parent_o.items():\n",
    "            # generate dataset and add to `datasets`\n",
    "            pass\n",
    "        \n",
    "        for parent, observations in self.child_otarget.items():\n",
    "            # generate dataset and add to `datasets`\n",
    "            pass\n",
    "        \n",
    "        # get compression format\n",
    "        root_path, extension = os.path.splitext(path)\n",
    "        \n",
    "        # make uncompressed dir\n",
    "        head, tail = os.path.split(path)\n",
    "        # TODO: create dir at `head` named `tail`\n",
    "        \n",
    "        # collectively save all datasets\n",
    "        for name, dataset in datasets.items():\n",
    "            #TODO: save compressed `dataset` at `os.path.join(root_path,name)`\n",
    "        \n",
    "        # finally, compress the containing dir\n",
    "        # TODO select appropriate compression algorithm\n",
    "        # TODO actually compress and save dir with pathname `path`\n",
    "        \n",
    "        raise NotImplemented()\n",
    "        \n",
    "    def load_information_episode(self, path):\n",
    "        \"\"\"\n",
    "        load data to `self.parent_o` and `self.child_otarget`\n",
    "        from `path` for training. Keeps existing data, but\n",
    "        override records when found in file at `path`\n",
    "        \n",
    "        NOTE: `self.parent_otarget` and `self.s` are\n",
    "        not loaded by this call. To ensure a completely new\n",
    "        information episode is loaded, you should\n",
    "        `reset_information_episode` prior to loading another.\n",
    "        \n",
    "        This does NOT include subclass definitions, hyperparameters, etc.\n",
    "        Those entities must be reconstructed and then `load_information_episode`\n",
    "        \n",
    "        :param path: savepath\n",
    "                \n",
    "                The suffix of `path` detirmines decompression\n",
    "                employed. Valid options are: '.zip', '.gz', and '.bz2'\n",
    "                \n",
    "                `path` must use existing directories\n",
    "        \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        raise NotImplemented()\n",
    "\n",
    "    def reset_information_episode(self):\n",
    "        \"\"\"\n",
    "        resets all inference stateful variables\n",
    "        including observations and internal states\n",
    "\n",
    "        This means clearing:\n",
    "            `self.child_otarget`,\n",
    "            `self.parent otarget`,\n",
    "            `self.parent_o`,\n",
    "            and `self.s` dictionaries\n",
    "            \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        self.child_otarget.clear()\n",
    "        self.parent_otarget.clear()\n",
    "        self.s.clear()\n",
    "        self.parent_o.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cLGvvSR2-aeF"
   },
   "outputs": [],
   "source": [
    "class Sensory_Node(Node):\n",
    "\n",
    "    def __init__(self, sensing_func):\n",
    "        \"\"\"\n",
    "        initialize `Sensory_Node`\n",
    "        \n",
    "        :param sensing_func: function (time) -> observation\n",
    "                used to interface with external environments\n",
    "                \n",
    "                use decorators to succintly initialize\n",
    "                \n",
    "        :param rand_obs: default `False`. whether or not `sensing_func`\n",
    "                returns a 2D tensor (the second axis represents random\n",
    "                variational values)\n",
    "                \n",
    "        :return: initialized `Sensory_Node`\n",
    "        \"\"\"\n",
    "        self.sensing_func = sensing_func\n",
    "        self.rand_obs = rand_obs\n",
    "    \n",
    "    def update(self, time):\n",
    "        \"\"\"\n",
    "        records sensory observation in `self.s[time]`.\n",
    "        Sensory observation taken from `self.sensing_func`\n",
    "        \n",
    "        :param time: node time when updated\n",
    "\n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        self.s[time] = self.sensing_func(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wbAGtvlK-cHd"
   },
   "outputs": [],
   "source": [
    "class Actuator_Node(Node):\n",
    "\n",
    "    def __init__(self,\n",
    "                 acting_func,\n",
    "                 sensing_func=None,\n",
    "                 samples=1,\n",
    "                 rand_obs=False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        initialize `Sensory_Node`\n",
    "        \n",
    "        :param acting_func: function (time, target_observation) -> None\n",
    "                used to interface with external environments\n",
    "                \n",
    "                use decorators to succintly initialize\n",
    "        \n",
    "        :param sensing_func: function (time) -> observation\n",
    "                used to interface with external environments\n",
    "                \n",
    "                If `None`, target state is assumed to be\n",
    "                executed perfectly\n",
    "                \n",
    "        :param samples: since the weighted mean child target \n",
    "                observation states may be probablistic, they are sampled\n",
    "                for `self.samples` times to compute mean expectations.\n",
    "                set to `-1` to directly pass all samples to acting func\n",
    "                \n",
    "        :param rand_obs: default `False`. whether or not `sensing_func`\n",
    "                returns a 2D tensor (the second axis represents random\n",
    "                variational values)\n",
    "                \n",
    "        :return: initialized `Actuator_Node`\n",
    "        \"\"\"\n",
    "        \n",
    "        if sensing_func is None:\n",
    "            if rand_obs:\n",
    "                warnings.warn('There will be no random variation'\n",
    "                              + ' in percieved actions since'\n",
    "                              + ' default perfect execution is assumed')\n",
    "            def default_sensing_func(time)\n",
    "            sensing_func\n",
    "            \n",
    "        self.acting_func = acting_func\n",
    "        self.sensing_func = sensing_func\n",
    "        self.samples = samples\n",
    "        self.rand_obs = rand_obs\n",
    "        \n",
    "        super(Actuator_Node, self).__init__(**kwargs)\n",
    "        \n",
    "    def update(self, time):\n",
    "        \"\"\"\n",
    "        attempts to act out the weighted mean child target observation.\n",
    "        Since target states may be probablistic, they are sampled\n",
    "        for `self.samples` times to compute mean expectations\n",
    "        \n",
    "        :param time: node time when updated\n",
    "\n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        # record actual action perform at previous timestep\n",
    "        if time - self.p >= 0:\n",
    "            self.s.append(self.sensing_func(time))\n",
    "        \n",
    "        # compute target state\n",
    "        starget = self.child_obs_target_weighted_mean(time)\n",
    "        \n",
    "        # sample target state\n",
    "        if self.samples != -1:\n",
    "            starget = tf.reduce_mean(starget, axis=1)\n",
    "        \n",
    "        # act out target state\n",
    "        self.acting_func(starget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "il4MJ571-eYs"
   },
   "outputs": [],
   "source": [
    "class Information_Node(Node):\n",
    "\n",
    "    \n",
    "    def __init__(self, \n",
    "                 abstractor,\n",
    "                 predictor,\n",
    "                 policy,\n",
    "                 params = {\n",
    "                    \"pred-weight\":None,\n",
    "                    \"alpha-d1\":None,\n",
    "                    \"alpha-d2\":None,\n",
    "                    \"alpha-d3\":None\n",
    "                 },   \n",
    "                 ):\n",
    "        \"\"\"\n",
    "        initialize an `Information_Node`\n",
    "        \n",
    "        :return: returns initialized `Information_Node`\n",
    "        \"\"\"\n",
    "        \n",
    "        self.params = params\n",
    "        self.abstractor\n",
    "        self.predictor\n",
    "        self.policy\n",
    "\n",
    "    def update(self, time):\n",
    "        \"\"\"\n",
    "        updates \n",
    "        \n",
    "        :param time: node time when updated\n",
    "\n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        #TODO\n",
    "        \n",
    "        # scramble values along random axis to increase randomness\n",
    "        # TODO\n",
    "        \n",
    "        raise NotImplemented()\n",
    "\n",
    "    def train(self,\n",
    "              lr=0.001,\n",
    "              verbose=True,\n",
    "              beta_piD=1,\n",
    "              beta_piC=1,\n",
    "              beta_piI=1,\n",
    "              beta_prD=1,\n",
    "              beta_prC=1,\n",
    "              ):\n",
    "        \"\"\"\n",
    "        trains `Information_Node` from data\n",
    "        stored in `self.parent_o` and `self.child_otarget`\n",
    "\n",
    "        :param lr: learning rate for optimizer\n",
    "        :param verbose: (True/False) log information verbosely\n",
    "        :param beta_piD: training hyperparameter. See 'Putting It All Togethor'\n",
    "        :param beta_piC: training hyperparameter. See 'Putting It All Togethor'\n",
    "        :param beta_piI: training hyperparameter. See 'Putting It All Togethor'\n",
    "        :param beta_prD: training hyperparameter. See 'Putting It All Togethor'\n",
    "        :param beta_prC: training hyperparameter. See 'Putting It All Togethor'\n",
    "        \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        #TODO\n",
    "        raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \n",
    "    def __init__(self, nodes):\n",
    "        \"\"\"\n",
    "        initializes the network\n",
    "        \n",
    "        :param nodes: all nodes that should be managed by the network. \n",
    "        \n",
    "        :return: returns initialized network\n",
    "        \"\"\"\n",
    "        self.nodes = nodes\n",
    "        self.time = 0\n",
    "    \n",
    "    def run(self, duration=-1, timestep=1):\n",
    "        \"\"\"\n",
    "        loops until time == duration\n",
    "        \n",
    "        :param duration: time to run for. -1 means forever\n",
    "        :param timestep: time increments used during `step`\n",
    "        \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        while self.time <= duration:\n",
    "            self.step(timestep)\n",
    "    \n",
    "    def step(self, timestep):\n",
    "        \"\"\"\n",
    "        increase timestep and check if any nodes should be updated\n",
    "        \n",
    "        :param timestep: positive time increment used\n",
    "        \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        self.time += timestep\n",
    "        #TODO\n",
    "        raise NotImplemented()\n",
    "    \n",
    "    def save_episode(self, path):\n",
    "        \"\"\"\n",
    "        saves stateful data to `path` in for training later.\n",
    "        \n",
    "        This does NOT save architecture, node class definitions,\n",
    "        hyperparameters, etc. The network must be reconstructed\n",
    "        and then records are added by `load_episode`\n",
    "        \n",
    "        :param path: filepath to compressed archive containing\n",
    "                saved Node information_episodes\n",
    "                \n",
    "                The suffix of `path` detirmines compression\n",
    "                employed. Valid options are: '.zip', '.gz', and '.bz2'\n",
    "                \n",
    "                `path` must use existing directories\n",
    "        \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        #TODO\n",
    "        raise NotImplemented()\n",
    "    \n",
    "    def load_episode(self, path):\n",
    "        \"\"\"\n",
    "        Calls `load_information_episode` for all nodes\n",
    "        with training records found at `path`. \n",
    "        \n",
    "        NOTE: `Node.load_information_episode` has non-\n",
    "        idempotent behavior. See definition for details\n",
    "        \n",
    "        This does NOT restore architecture, node class definitions,\n",
    "        hyperparameters, etc. The network must be reconstructed\n",
    "        and then records are added by `load_episode`\n",
    "        \n",
    "        :param path: filepath to compressed archive containing\n",
    "                saved Node information_episodes\n",
    "                \n",
    "                The suffix of `path` detirmines decompression\n",
    "                employed. Valid options are: '.zip', '.gz', and '.bz2'\n",
    "                \n",
    "                `path` must use existing directories\n",
    "        \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        #TODO\n",
    "        raise NotImplemented()\n",
    "    \n",
    "    def reset_episode(self):\n",
    "        \"\"\"\n",
    "        resets all nodes' inference stateful variables\n",
    "        including observations and internal states\n",
    "            \n",
    "        :return: returns nothing\n",
    "        \"\"\"\n",
    "        #TODO\n",
    "        raise NotImplemented()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPZdmxyqEAjoQbH17fXsq9p",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Nodal RL core.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
